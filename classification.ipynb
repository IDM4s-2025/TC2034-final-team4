{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37669dd4",
   "metadata": {},
   "source": [
    "Team members:\n",
    "- Sophia Gabriela Martinez Albarran A01424430\n",
    "- Eduardo Botello Casey A01659281\n",
    "- Marcos Saade Romano A01784220"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21663611",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y). It contains 6 integers variables and 11 categorical variables. It has 45211 instances of data, where we will be performing a cleaning and preprocessing before creating the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8f8eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "  \n",
    "# https://archive.ics.uci.edu/dataset/222/bank+marketing  \n",
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = bank_marketing.data.features \n",
    "y = bank_marketing.data.targets \n",
    "  \n",
    "# Drop the column duration because in the page it says it isn't necessary for a predictive model\n",
    "X = X.drop(columns=['duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf595f",
   "metadata": {},
   "source": [
    "Duration was removed based on the dataset documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df2c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          45211 non-null  int64 \n",
      " 1   job          44923 non-null  object\n",
      " 2   marital      45211 non-null  object\n",
      " 3   education    43354 non-null  object\n",
      " 4   default      45211 non-null  object\n",
      " 5   balance      45211 non-null  int64 \n",
      " 6   housing      45211 non-null  object\n",
      " 7   loan         45211 non-null  object\n",
      " 8   contact      32191 non-null  object\n",
      " 9   day_of_week  45211 non-null  int64 \n",
      " 10  month        45211 non-null  object\n",
      " 11  campaign     45211 non-null  int64 \n",
      " 12  pdays        45211 non-null  int64 \n",
      " 13  previous     45211 non-null  int64 \n",
      " 14  poutcome     8252 non-null   object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50224caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance   day_of_week      campaign         pdays  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419      2.763841     40.197828   \n",
       "std       10.618762    3044.765829      8.322476      3.098021    100.128746   \n",
       "min       18.000000   -8019.000000      1.000000      1.000000     -1.000000   \n",
       "25%       33.000000      72.000000      8.000000      1.000000     -1.000000   \n",
       "50%       39.000000     448.000000     16.000000      2.000000     -1.000000   \n",
       "75%       48.000000    1428.000000     21.000000      3.000000     -1.000000   \n",
       "max       95.000000  102127.000000     31.000000     63.000000    871.000000   \n",
       "\n",
       "           previous  \n",
       "count  45211.000000  \n",
       "mean       0.580323  \n",
       "std        2.303441  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max      275.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a851b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.job = X.job.fillna('unknown')\n",
    "X.education = X.education.fillna('unknown')\n",
    "X.poutcome = X.poutcome.fillna('nonexistent')\n",
    "X.contact = X.contact.fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9997f0b",
   "metadata": {},
   "source": [
    "Missing values in categorical variables were replaced with unknown in the database. \n",
    "\n",
    "Rather than deleting data, these values were preserved as valid categories.\n",
    "\n",
    "One-hot encoding will later treat them as distinct features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1f3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X.select_dtypes(include=['object']))\n",
    "X_encoded_df = pd.DataFrame(\n",
    "    X_encoded.toarray(), \n",
    "    columns=encoder.get_feature_names_out(X.select_dtypes(include=['object']).columns)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542dc07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerico = X.select_dtypes(exclude=['object'])\n",
    "X_final = pd.concat([X_numerico.reset_index(drop=True), X_encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda430f1",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier \n",
    "\n",
    "Logistic Regression is widely used for binary classification problems and serves as an interpretable and effective baseline.\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "- Interpretability: The model's coefficients indicate the direction and strength of each feature’s influence on the prediction.\n",
    "\n",
    "- Efficiency: Training and inference are fast, even with large datasets.\n",
    "\n",
    "- Probabilistic Output: It provides confidence scores for predictions.\n",
    "\n",
    "- Built-in Regularization: It supports L2 regularization to reduce overfitting.\n",
    "\n",
    "### Disadvantages \n",
    "\n",
    "- Assumes a linear relationship between the input features and the log-odds of the outcome.\n",
    "\n",
    "- Sensitive to feature scaling, requiring standardized numeric features.\n",
    "\n",
    "- Not suitable for nonlinear relationships unless combined with feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_col = X.select_dtypes(include='object').columns.tolist()\n",
    "num_col = X.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, cat_col),\n",
    "        ('num', numerical_transformer, num_col)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64598066",
   "metadata": {},
   "source": [
    "To ensure proper and consistent preprocessing of both categorical and numerical variables, we created a structured pipeline using ColumnTransformer and Pipeline. \n",
    "This approach is modular, safe against data leakage, and compatible with cross-validation and model tuning.\n",
    "\n",
    "It automatically identifies categorical columns (those with object dtype) and stores them in cat_col, it stores the remaining numerical columns in num_col.\n",
    "\n",
    "Then:\n",
    "\n",
    "- OneHotEncoder: Converts each categorical column into a set of binary columns (0 or 1), one per category. It uses handle_unknown='ignore' to safely handle categories that might appear in new data but were not seen during training.\n",
    "\n",
    "- StandardScaler: Standardizes numerical features by removing the mean and scaling to unit variance.\n",
    "\n",
    "We use it because Logistic Regression is sensitive to feature scale, so we need standardized inputs for numeric features, and categorical variables must be encoded into numbers for the model to process them.\n",
    "\n",
    "Then we built a preprocessing object that applies categorical_transformer to the categorical columns, and numerical_transformer to the numeric columns.It also applies different transformations in parallel and ensures each set of columns is processed as needed. It also integrates smoothly into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = y['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0c5d3",
   "metadata": {},
   "source": [
    "The target variable y originally consisted of categorical values 'yes' and 'no'. These were converted into binary numeric values 1 and 0 respectively using .map(). This transformation was required to make the data compatible with scikit-learn classifiers, which expect numeric labels. This also formalizes the task as a binary classification problem\n",
    "\n",
    "Then the dataset was split into training (80%) and test (20%) subsets using train_test_split(). The stratify=y parameter was used to maintain the original proportion of classes in both sets, which is particularly important for imbalanced classification problems. Additionally, random_state=42 was used to ensure that the split is reproducible, making the results consistent across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cabe356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_logisticreg_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b8737",
   "metadata": {},
   "source": [
    "Hyperparameter tuning was performed using GridSearchCV with 5-fold cross-validation. A grid of candidate values was defined for C, the regularization strength of the Logistic Regression model. We fixed the penalty to L2 and used the lbfgs solver due to its efficiency with this penalty. The model was evaluated using the ROC AUC metric during cross-validation, which is appropriate for this imbalanced classification task. The best pipeline configuration was stored in best_logisticreg_model and used for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0bf8449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'lbfgs'}\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      7985\n",
      "           1       0.67      0.17      0.27      1058\n",
      "\n",
      "    accuracy                           0.89      9043\n",
      "   macro avg       0.79      0.58      0.61      9043\n",
      "weighted avg       0.87      0.89      0.86      9043\n",
      "\n",
      "Matriz de Confusión:\n",
      " [[7897   88]\n",
      " [ 877  181]]\n",
      "ROC AUC: 0.7725529791800079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "y_pred = best_logisticreg_model.predict(X_test)\n",
    "y_proba = best_logisticreg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44b1ae",
   "metadata": {},
   "source": [
    "The model achieves high precision (0.67) on the positive class (yes), meaning that when it predicts a client will subscribe, it is often correct.\n",
    "\n",
    "However, it has low recall (0.17) on that same class, indicating that it misses a large portion of the actual positives.\n",
    "\n",
    "This imbalance is common in datasets with skewed class distribution (most clients do not subscribe).\n",
    "\n",
    "The high overall accuracy (0.89) is influenced by the model’s strong performance on the dominant class (no), but it may not be sufficient for applications where detecting potential subscribers is critical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
